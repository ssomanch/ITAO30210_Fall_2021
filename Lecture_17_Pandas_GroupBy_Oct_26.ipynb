{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Indexing\n",
    "\n",
    "### Multiindex\n",
    "\n",
    "If you set an index to more than one columnn you are creating multi index or Hieararchical index. This makes asking questions based on indexes a lot more easier, and also opens the possibility of working with multidimensional data. \n",
    "\n",
    "We'll use the example sourced from [here](https://chrisalbon.com/python/pandas_hierarchical_data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
    "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
    "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
    "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
    "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting an index of an existing `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_ind = df.set_index('regiment')\n",
    "df_1_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_ind.mean(level = 'regiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hierarchical index to be by regiment, and then by company\n",
    "df_2_ind = df.set_index(['regiment', 'company'])\n",
    "df_2_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "Having multiple indexes will give you an easy way to model more than two dimensional data with DataFrames. Remember DataFraemes are by default a two dimensional data structures. \n",
    "</p>\n",
    "<p>\n",
    "For the above example, you can imagine each regiment is a two-dimensional array giving details about the company, names and the scores, and they are stacked one below the other. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How about you want to get the mean scores, based on the company but not the regiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level='regiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_ind.mean(level=['regiment','company'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Aggregation\n",
    "\n",
    "We have already seen some simple aggregations on Pandas **`Series`** and **`DataFrame`** objects.\n",
    "\n",
    "Let us review a few aggregation functions that will help us in understanding the **Grouping**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using our college scorecard dataset in this tutorial.\n",
    "college_scorecard = pd.read_csv('./data/college-scorecard-data-scrubbed.csv', \n",
    "    encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "Remember, that a series actually holds its values in a nested NumPy array (ndarray) object. Pandas simply has to apply these aggregations functions to that nested array.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of available `Series` and `DataFrame` aggregation methods from your textbook.\n",
    "\n",
    "| Aggregation Function      | Description    |      \n",
    "|---------------|---------------------|\n",
    "|count()        |Total number of items (not including NaN)|\n",
    "|first(), last()|First and last item  |\n",
    "|mean(), median()  |Mean and median   |\n",
    "|min(), max()   |Minimum and Maximum  |\n",
    "|std(), var()   |Standard deviation & variance |\n",
    "|mad()          |Mean absolute deviation |\n",
    "|prod()         |Product of all items         |\n",
    "|sum()          |Sum of all items           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `describe()` method\n",
    "The `describe()` method is available on both **`Series`** and **`DataFrame`** objects and outputs a variety of aggregations that are very useful in getting the general \"sense\" of a dataset.\n",
    "\n",
    "Take a look at the output for our **`sat_average`** series and **`college_scorecard`** dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_averages = college_scorecard['sat_average']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_averages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweaking `describe()` behavior with `include` and `exclude` parameters.\n",
    "When used on a **`DataFrame`** object, the default behavior of the **`describe()`** method is to provide statistics on numeric columns only.\n",
    "\n",
    "Let's take a look at the **`dtypes`** attribute on our college_scorecard dataframe to see what columns this does/doesn't include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_scorecard.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>\n",
    "The `dtype` attribute of `DataFrame` objects returns information on the datatype of each nested series/column.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all the places where it lists the datatype of a column as 'object'? These columns won't be reported on with **`describe()`** when using the default parameters.\n",
    "\n",
    "We can change this using either the **`include`** or the **`exclude`** parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the object datatype columns\n",
    "college_scorecard.describe(include= [np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the numeric datatypes\n",
    "college_scorecard.describe(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things here to notice:\n",
    "1. The type of statistics returned changed when operating on **`object`** column types.\n",
    "2. I used NumPy datatypes in the specification of what to include and exclude.\n",
    "\n",
    "**The Statistics**  \n",
    "Object(esp. string based) columns cannot be summarized reasonably with many of numeric aggregations so Pandas gives an alternative set of aggregations which make more sense for this type of data.\n",
    "\n",
    "**NumPy Datatypes**  \n",
    "Remember that the values of each `Series` inside of a `DataFrame` are stored in a NumPy array. Therefore the elements in that NumPy array are described by NumPy datatypes.\n",
    "\n",
    "That is why we specify NumPy datatypes here to specifically include/exclude them for Pandas `describe` method.\n",
    "\n",
    "This is just another example of the tight integration between the two libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can specify **`include='all'`** to force Pandas\n",
    "# to evaluate all columns.  It will inject NaN where\n",
    "# a calculation cannot be done.\n",
    "college_scorecard.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will look at the sample dataset of the flight schedules data that is available on Kaggle [here](https://www.kaggle.com/usdot/flight-delays)\n",
    "\n",
    "This is only a sample of the original data. You will use the original data in your Group Project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('./data/flight_sample.csv')\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `groupby()` Method\n",
    "\n",
    "So far, all the calculations that we've done on **`DataFrame`** objects have looked at the values of columns as a whole.\n",
    "\n",
    "The `groupby()` method allows you to move into deeper forms analysis by splitting up the rows of a dataset into groups by the values in specified row(s). You can think of this in some ways as putting rows into buckets for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying how to Split your Dataset into Groups\n",
    "Of course, before we can perform evaluations on groups, we have to create them from an existing dataframe. \n",
    "\n",
    "Let's explore how **`groupby()`** provides a variety of ways to split up your datasets. We'll explore some of these here, starting with the most simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Column Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THIS IS ONLY SHOWING GROUPS, LOOK BELOW ON HOW TO USE THE GROUPS\n",
    "flights_by_airline = flights.groupby(['AIRLINE'])\n",
    "flights_by_airline.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`groupby()`** method returns an type called **`DataFrameGroupBy`**. We will explore it in more depth shortly, but for now just know that it has an attribute called **`groups`** which provides a *`dict`* object with the **labels** of each group and the **corresponding index values** in the original dataframe that belong to that group.\n",
    "\n",
    "If you look above, you can see there is a group labelled 'AA' will index values [2,   19,   43,   55,   59,   64,   71,   74,   82,   92, ...].\n",
    "\n",
    "You can think of this as a record of all the groups that we will perform calculations on later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Column Grouping\n",
    "\n",
    "You can specify multiple columns if you wish to split your data up in multiple levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THIS IS ONLY SHOWING GROUPS, LOOK BELOW ON HOW TO USE THE GROUPS\n",
    "flights_by_airline_month = flights.groupby(['AIRLINE', 'MONTH'])\n",
    "flights_by_airline_month.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations after GroupBy\n",
    "\n",
    "For example, let us say you want to find out the average distance traveled by each airline, you can do that using the following aggregeate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_by_airline = flights.groupby(['AIRLINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_by_airline = flights_by_airline[['DISTANCE', 'TAXI_IN']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The double [[ ]] for computing the summary stististics. The first pair [] is used to look into the `DataFrameGroupyBy` object the second pair [] is used to list all the columns you want to produce the summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_airline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "\n",
    "### Gerneralizing using GroupBy\n",
    "\n",
    "1\\. Use AIRLINE `groupby` records into a `DataFrameGroupBy` object?\n",
    "\n",
    "2\\. Compute the median distnace travelled per airline. \n",
    "\n",
    "3\\. Extract the median DISTANCE for SouthWest airlines (WN) and assign it a variable `median_distance_WN`. \n",
    "\n",
    "4\\. What is the median DISTANCE, TAXI_IN times and TAXI_OUT times per airline per month? \n",
    "\n",
    "5\\. Extract the median TAXI_OUT for SouthWest airlines (WN) in December (12) and assign it a variable `median_distance_WN_12`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 3\n",
    "median_distance_WN = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 5: Select WN airline in month 12, average TAXI_OUT\n",
    "median_distance_WN_12 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Aggregation After GroupBy: Method Dispatching\n",
    "\n",
    "Let us now understand how the Aggregations on the DataFrameGroupBy objects work. In the **`DataFrameGroupBy`** objects, any method not found on the object itself is forwarded (\"**dispatched**\") to all the groups that it contains.\n",
    "\n",
    "That is why we were able to ask for the *`median`* of a **`flights_by_airline`** object above and get something back: it is (1) \"dispatching\" the *`median`* method call to each group (that is each airline), (2) collecting the results and (3) presenting them to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_by_airline = flights.groupby(['AIRLINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the median for the entire DataFrameGroupBy object and then select 'DISTANCE' column \n",
    "flights_by_airline.median()[['DISTANCE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'DISTANCE' Column and then compute the median\n",
    "flights_by_airline[['DISTANCE']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Which of the above two methods should be preferred? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the 'DISTANCE' Column and then compute the median. THIS GIVES YOU SERIES OBJECT. \n",
    "flights_by_airline['DISTANCE'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Note difference between using double square brackets [[ ]] and single bracket [ ]. For example, ``flights_by_airline[['DISTANCE']].median()`` above is a Dataframe with one column, where as if you use `` flights_by_airline['DISTANCE'].median()`` it'll give you a Series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of `DataFrameGroupBy` Objects\n",
    "Now we will understand the various operations built into the `DataFrameGroupBy` object type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `aggregate()` Method\n",
    "At first, the `aggregate()` method appears to be quite similiar to what we just covered when we talked about method dispatching. It performs aggregations on the groups in a **`DataFrameGroupBy`** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline.aggregate('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that the **`aggregate()`** method gives you some additional options that are not available if you rely on method dispatching as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass multiple aggregates as a list.\n",
    "# Here will we get various aggregates for each\n",
    "# column of our flights_by_airline object.\n",
    "flights_by_airline.aggregate([np.mean, 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>\n",
    "It is important to notice that you are able to pass both strings and functions to the `aggregate()` method. It is probably best to choose one approach and stick with it rather than mixing and matching like I've done here.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline.aggregate([np.mean, np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your textbook also talks about using a dict to apply labels to the aggregation columns so that they can have user friendly names like 'Longest Distance' rather than just 'max'.\n",
    "\n",
    "This sort of functionality is, however, deprecated in Pandas, which means that it will be removed in future versions.\n",
    "\n",
    "To accomplish the same thing, we should instead append a `rename()` method after our `aggregate()` method like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `rename()` to apply friendly labels to output columns\n",
    "flights_by_airline['DISTANCE'].aggregate(\n",
    "    [np.mean, np.min, np.max]).rename(\n",
    "        columns={'mean': 'Avg. Distance', \n",
    "                 'amin': 'Shortest Distance', \n",
    "                 'amax': 'Longest Distance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<p>\n",
    "Note, there are three main things happening in the above statement. \n",
    "\n",
    "<li> flights_by_airline['DISTANCE'] selects the distance column for analysis\n",
    "<li> flights_by_airline['DISTANCE'].aggregate([np.mean, np.min, np.max]) computes the average, min and max of the distance column selected\n",
    "<li> Finally .rename() function is appropriately renaming the columns according the dictionary we have given  \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended way of using a **`dict`** with the **`aggregate()`** method is actually to specify which aggregation(s) to perform on what columns. You can use it to specify different aggregation(s) on a per-column basis.\n",
    "\n",
    "Here I'll use it to get the high/low values for DISTANCE and the mean for TAXI_IN on our *`flights_by_airline_month`* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airline_month = flights.groupby(['AIRLINE', 'MONTH'])\n",
    "\n",
    "# Notice how using this style automatically filters\n",
    "# out all columns you don't specify.\n",
    "flights_by_airline_month.aggregate(\n",
    "        {'DISTANCE': [np.min, np.max], \n",
    "         'TAXI_IN': np.mean}).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: \n",
    "\n",
    "We will work again on the `college-loan-default-rates.csv` and `college-scorecard-data-scrubbed.csv` datasets. \n",
    "\n",
    "Use `aggregate()` method to produce\n",
    "\n",
    "1. The average, minimum and maximum `full_time_retention_rate_4_year` per state using `college-scorecard-data-scrubbed.csv` dataset. \n",
    "    * After producing the above summary statistics, make sure you rename your columns for average, minimum and maximum as `Avg. Retention`, `Low Retention`, and `High Retention` respectively. \n",
    "\n",
    "2. Which state has the highest average four year retention rate (`full_time_retention_rate_4_year`)? Which has the lowest average? \n",
    "\n",
    "3. Produce per state and city, minimum and maximum for the `sat_average` column and average for the `full_time_retention_rate_4_year` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For this tutorial, we will need both of our datasets.\n",
    "college_loan_defaults = pd.read_csv(\n",
    "    './data/college-loan-default-rates.csv')\n",
    "\n",
    "college_scorecard = pd.read_csv(\n",
    "    './data/college-scorecard-data-scrubbed.csv', \n",
    "    encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1 (contd...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3> Important Notes</h3>\n",
    "<p> </p> \n",
    "When producing any of the summary statistics using group by, you can assign your intermediate operations to the variables. In the entire section above, I have been mostly trying to produce the results to show them to you. However, you can assign the results to a variable for using it in the future. **See the example below.** \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_by_airline_month = flights.groupby(['AIRLINE', 'MONTH'])\n",
    "summary_distanc_taxi_in = flights_by_airline_month.aggregate(\n",
    "        {'DISTANCE': [np.min, np.max], \n",
    "         'TAXI_IN': np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_distanc_taxi_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember from the last class that we can do aggregations at multiple levels using Hierarchical index. \n",
    "summary_distanc_taxi_in.mean(level='AIRLINE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
